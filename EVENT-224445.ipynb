{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504e37d4",
   "metadata": {},
   "source": [
    "### Name : Bilal Muhammad Khan\n",
    "### Gmail : drbilal216@gmail.com\n",
    "### My Competition Id : EVENT-224445"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8aa2c",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68bd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd127e98",
   "metadata": {},
   "source": [
    "## Downloading Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "891a0fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 638s 11us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2fb412",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e54f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               2097408   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16812353 (64.13 MB)\n",
      "Trainable params: 16812353 (64.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93418b",
   "metadata": {},
   "source": [
    "## freezing the convolutional base\n",
    "In Keras, you freeze a network by setting its trainable attribute to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b0e71fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights ''before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfc3d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc263176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    " print('This is the number of trainable weights ''after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da03c5",
   "metadata": {},
   "source": [
    "## Training the model end to end with a frozen convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46fb7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for train, validation and test datasets\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "validation_dir = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8b9cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be64b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1e1c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65f875c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5236 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_dir,\n",
    "                    target_size=(150, 150),\n",
    "                    batch_size=20,\n",
    "                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b64ba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                        validation_dir,\n",
    "                        target_size=(150, 150),\n",
    "                        batch_size=20,\n",
    "                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "225bc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0f45a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ESHOP\\AppData\\Local\\Temp\\ipykernel_6860\\3578974842.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3033 - acc: 0.8677WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 260s 3s/step - loss: 0.3033 - acc: 0.8677 - val_loss: 0.6182 - val_acc: 0.7500\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 252s 3s/step - loss: 0.2362 - acc: 0.8970\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 264s 3s/step - loss: 0.2215 - acc: 0.9063\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=100,\n",
    "                epochs=3,#30\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54965963",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION WITH DATA AUGMENTATION and Fine-tuning\n",
    "1 Add your custom network on top of an already-trained base network.\n",
    "\n",
    "2 Freeze the base network.\n",
    "\n",
    "3 Train the part you added.\n",
    "\n",
    "4 Unfreeze some layers in the base network.\n",
    "\n",
    "5 Jointly train both these layers and the part you added.\n",
    "\n",
    "You already completed the first three steps when doing feature extraction. Let’s proceed with step 4: you’ll unfreeze your conv_base and then freeze individual layers inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "185c3f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "516b1f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1031db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1db365c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39006258",
   "metadata": {},
   "source": [
    "#### Freezing all layers up to a specific one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d26d7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac162891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81701d74",
   "metadata": {},
   "source": [
    "#### Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92806823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fdfff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ESHOP\\AppData\\Local\\Temp\\ipykernel_6860\\113632108.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4916 - acc: 0.7380WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 286s 3s/step - loss: 1.4916 - acc: 0.7380 - val_loss: 0.8812 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 279s 3s/step - loss: 0.3587 - acc: 0.8595\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.2707 - acc: 0.8933\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 278s 3s/step - loss: 0.2386 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 273s 3s/step - loss: 0.2098 - acc: 0.9260\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 279s 3s/step - loss: 0.1775 - acc: 0.9425\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 295s 3s/step - loss: 0.1898 - acc: 0.9385\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 303s 3s/step - loss: 0.1784 - acc: 0.9409\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 298s 3s/step - loss: 0.1625 - acc: 0.9405\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 324s 3s/step - loss: 0.1801 - acc: 0.9444\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 # 100\n",
    "history = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=100,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa87903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "model.save('model_F.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61455d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8bd5e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "                    test_dir,\n",
    "                    target_size=(150, 150),\n",
    "                    batch_size=20,\n",
    "                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f3e9e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ESHOP\\AppData\\Local\\Temp\\ipykernel_6860\\1629466864.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.8717948794364929\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46482e36",
   "metadata": {},
   "source": [
    "## Saving it also in pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b0dac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving knn_user_model in binary mode \n",
    "Pickle = open('model', 'wb')\n",
    "pickle.dump(model, Pickle)  \n",
    "# close the file\n",
    "Pickle.close()\n",
    "#################\n",
    "# Saving knn_model_user_movie in binary mode \n",
    "Pickle = open('model', 'wb')\n",
    "pickle.dump(model, Pickle)  \n",
    "# close the file\n",
    "Pickle.close()\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7e769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
